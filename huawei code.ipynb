{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijKLRBcjP3Q0"
      },
      "outputs": [],
      "source": [
        "#import the libraries:\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from random import shuffle\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm9rddjQI3VM"
      },
      "outputs": [],
      "source": [
        "# unzipping the file:\n",
        "!unzip /content/BAU_HW_CAT_DOG_CLASSIFICATION.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9AEdpxZP3TQ",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# implementing the preprocessing functions: \n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_images_labels(dir, label):\n",
        "    \"\"\"Loads images and labels from a directory.\n",
        "\n",
        "    Args:\n",
        "        dir: string, path to the directory to load images from.\n",
        "        label: int, label for the images.\n",
        "\n",
        "    Returns:\n",
        "        images: list of NumPy arrays, images in the directory.\n",
        "        labels: list of ints, labels for the images.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "        image = cv2.imread(os.path.join(dir, file))\n",
        "        image = cv2.resize(image, (200, 200))\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def normalize_images(images):\n",
        "    \"\"\"Normalizes images.\n",
        "\n",
        "    Args:\n",
        "        images: list of NumPy arrays, images to normalize.\n",
        "\n",
        "    Returns:\n",
        "        normalized_images: list of NumPy arrays, normalized images.\n",
        "    \"\"\"\n",
        "    normalized_images = []\n",
        "    for image in images:\n",
        "        normalized_images.append(image / 255.0)\n",
        "    return normalized_images\n",
        "\n",
        "def combine_images_labels(images_1, labels_1, images_2, labels_2):\n",
        "    \"\"\"Concatenates images and labels.\n",
        "\n",
        "    Args:\n",
        "        images_1: list of NumPy arrays, first set of images.\n",
        "        labels_1: list of ints, first set of labels.\n",
        "        images_2: list of NumPy arrays, second set of images.\n",
        "        labels_2: list of ints, second set of labels.\n",
        "\n",
        "    Returns:\n",
        "        combined_images: NumPy array, concatenation of images_1 and images_2.\n",
        "        combined_labels: NumPy array, concatenation of labels_1 and labels_2.\n",
        "    \"\"\"\n",
        "    combined_images = np.concatenate((images_1, images_2))\n",
        "    combined_labels = np.concatenate((labels_1, labels_2))\n",
        "    return combined_images, combined_labels\n",
        "\n",
        "# implementing the data paths:\n",
        "train_dir = '/content/BAU_HW_CAT_DOG_CLASSIFICATION/training_set'\n",
        "test_dir = '/content/BAU_HW_CAT_DOG_CLASSIFICATION/test_set'\n",
        "\n",
        "# loading and normalizing images and labels for the training set:\n",
        "\n",
        "\n",
        "x_train_cats, y_train_cats = load_images_labels(\n",
        "os.path.join(train_dir, 'cats'), 1)\n",
        "x_train_cats = normalize_images(x_train_cats)\n",
        "\n",
        "x_train_dogs, y_train_dogs = load_images_labels(\n",
        "os.path.join(train_dir, 'dogs'), 0)\n",
        "x_train_dogs = normalize_images(x_train_dogs)\n",
        "\n",
        "# normalization \n",
        "\n",
        "x_test_cats, y_test_cats = load_images_labels(\n",
        "os.path.join(test_dir, 'cats'), 1)\n",
        "x_test_cats = normalize_images(x_test_cats)\n",
        "\n",
        "x_test_dogs, y_test_dogs = load_images_labels(\n",
        "os.path.join(test_dir, 'dogs'), 0)\n",
        "x_test_dogs = normalize_images(x_test_dogs)\n",
        "\n",
        "# concatenatination\n",
        "\n",
        "x_train, y_train = combine_images_labels(\n",
        "x_train_cats, y_train_cats, x_train_dogs, y_train_dogs)\n",
        "\n",
        "#making training and testing sets:\n",
        "\n",
        "x_test, y_test = combine_images_labels(\n",
        "x_test_cats, y_test_cats, x_test_dogs, y_test_dogs)\n",
        "x_valid, y_valid = x_train[:1000], y_train[:1000]\n",
        "x_train, y_train = x_train[1000:], y_train[1000:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMwyYdFZIFfH"
      },
      "outputs": [],
      "source": [
        "# Model 1:\n",
        "model = models.Sequential()\n",
        "\n",
        "# Convolution Layers:\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "#Fully connected layers and output:\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling:\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Kfold with 5folds\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Istoring the predictions:\n",
        "predictions = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for train_index, test_index in kfold.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "    history = model.fit(x_train_fold, y_train_fold, epochs= 20, batch_size=64, validation_data=(x_test_fold, y_test_fold))\n",
        "    test_loss, test_acc = model.evaluate(x_test_fold, y_test_fold)\n",
        "    print('Fold test accuracy:', test_acc)\n",
        "\n",
        "    # Plotting as required: \n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss Curves')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])\n",
        "    plt.show()\n",
        "\n",
        "    # Evaluation on test data\n",
        "    _, accuracy = model.evaluate(x_test_fold, y_test_fold)\n",
        "    predictions.append(accuracy)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "5amJrc-QHRbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation on test data:\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "#Evaluation on train data:\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('Train accuracy:', train_acc)\n",
        "\n",
        "# mean accuracy across of the 5 folds\n",
        "mean_accuracy = np.mean(predictions)\n",
        "print('Mean accuracy:', mean_accuracy)"
      ],
      "metadata": {
        "id": "illSlimqIwqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWmelrEuIFfM"
      },
      "outputs": [],
      "source": [
        "# Model 2: Since the models and evaluation are the construvtion, no need for the same comments again:\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='sigmoid', input_shape=(200, 200, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='sigmoid')) \n",
        "model.add(layers.MaxPooling2D((2, 2))) \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='sigmoid'))\n",
        "model.add(layers.Dense(128, activation='sigmoid'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "predictions = []\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for train_index, test_index in kfold.split(x_train):\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "    history = model.fit(x_train_fold, y_train_fold, epochs=20, batch_size=64, validation_data=(x_test_fold, y_test_fold))\n",
        "    test_loss, test_acc = model.evaluate(x_test_fold, y_test_fold)\n",
        "    print('Fold test accuracy:', test_acc)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss Curves')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])\n",
        "    plt.show()\n",
        "\n",
        "    _, accuracy = model.evaluate(x_test_fold, y_test_fold)\n",
        "    predictions.append(accuracy)\n"
      ],
      "metadata": {
        "id": "gIXTIyYnJHu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_accuracy = np.mean(predictions)\n",
        "print('Mean accuracy:', mean_accuracy)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('Training accuracy:', train_acc)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Testing accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "MuuEJWzoJRw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqa7fq__IFfP",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Model 3: \n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='sigmoid')) \n",
        "model.add(layers.MaxPooling2D((2, 2))) \n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='sigmoid'))\n",
        "model.add(layers.Dense(128, activation='sigmoid'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "predictions = []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for train_index, test_index in kfold.split(x_train):\n",
        "\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  \n",
        "    history = model.fit(x_train_fold, y_train_fold, epochs=20, batch_size=64, validation_data=(x_test_fold, y_test_fold))\n",
        "    test_loss, test_acc = model.evaluate(x_test_fold, y_test_fold)\n",
        "    print('Fold test accuracy:', test_acc)\n",
        "\n",
        "    \n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss Curves')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "    _, accuracy = model.evaluate(x_test_fold, y_test_fold)\n",
        "\n",
        "    \n",
        "    predictions.append(accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "zXw0oHi3LLIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Testing accuracy:', test_acc)\n",
        "\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('Training accuracy:', train_acc)\n",
        "\n",
        "\n",
        "mean_accuracy = np.mean(predictions)\n",
        "print('Mean accuracy:', mean_accuracy)\n"
      ],
      "metadata": {
        "id": "q5E-xMiNLNv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOpYHKcmIFfS"
      },
      "outputs": [],
      "source": [
        "# Model 4: \n",
        "\n",
        "resnet = ResNet50(include_top=False, input_shape=(200, 200, 3))\n",
        "model = Sequential()\n",
        "model.add(resnet)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "predictions = []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for train_index, test_index in kfold.split(x_train):\n",
        "\n",
        "    x_train_fold, x_test_fold = x_train[train_index], x_train[test_index]\n",
        "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "    \n",
        "    history = model.fit(x_train_fold, y_train_fold, epochs=20, batch_size=64, validation_data=(x_test_fold, y_test_fold))\n",
        "\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(x_test_fold, y_test_fold)\n",
        "    print('Fold test accuracy:', test_acc)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Loss Curves')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'])\n",
        "    plt.show()\n",
        "    _, accuracy = model.evaluate(x_test_fold, y_test_fold)\n",
        "    predictions.append(accuracy)\n"
      ],
      "metadata": {
        "id": "Mjl_CSizMdJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Testing accuracy:', test_acc)\n",
        "\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "print('Training accuracy:', train_acc)\n",
        "\n",
        "\n",
        "mean_accuracy = np.mean(predictions)\n",
        "print('Mean accuracy:', mean_accuracy)"
      ],
      "metadata": {
        "id": "HaB9WP_dMeOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doOsyax4M445"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}